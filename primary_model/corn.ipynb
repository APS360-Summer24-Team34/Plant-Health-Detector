{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "csZky4M9Jopc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5uLKNu6pLlPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFaiKQetJdL8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.conv1(x))\n",
        "        x = self.pool(self.conv2(x))\n",
        "        x = self.pool(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)  # Flattening the tensor\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "class ModifiedResNet(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(ModifiedResNet, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(in_features, 256)\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "1sT_xlMCJzHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining both networks\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.custom_cnn = CustomCNN(num_classes)\n",
        "        self.modified_resnet = ModifiedResNet(num_classes)\n",
        "        self.fc = nn.Linear(256 * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        custom_out = self.custom_cnn(x)\n",
        "        resnet_out = self.modified_resnet(x)\n",
        "        combined_out = torch.cat((custom_out, resnet_out), dim=1)\n",
        "        out = self.fc(combined_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "7IT4FYZOJ_hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Check for GPU availability and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#functions below are the ones used in lab2/lab3 of APS360\n",
        "def evaluate(net, loader, criterion):\n",
        "    net.eval()\n",
        "    total_loss = 0.0\n",
        "    total_err = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "            total_err += (predicted != labels).sum().item()\n",
        "    accuracy = total_correct / total_samples\n",
        "    err = float(total_err) / total_samples\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return accuracy, err, loss\n",
        "\n",
        "\n",
        "def loader(train_images, val_images, test_images, batch_size=64):\n",
        "    train_loader = torch.utils.data.DataLoader(train_images, batch_size=batch_size, num_workers=2, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_images, batch_size=batch_size, num_workers=2, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_images, batch_size=batch_size, num_workers=2, shuffle=True)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def train(model, train_images, val_images, test_images, batch_size=64, lr=0.001, num_epochs=30):\n",
        "    torch.manual_seed(10)\n",
        "\n",
        "    # Move the model to GPU\n",
        "    model.to(device)\n",
        "\n",
        "    train_loader, val_loader, test_loader = loader(train_images, val_images, test_images, batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "    train_err = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    val_err = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        total_train_err = 0.0\n",
        "        total_train_correct = 0\n",
        "        total_train_samples = 0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            labels = labels.long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train_correct += (predicted == labels).sum().item()\n",
        "            total_train_samples += labels.size(0)\n",
        "            total_train_loss += loss.item()\n",
        "            total_train_err += (predicted != labels).sum().item()\n",
        "\n",
        "        train_acc[epoch] = total_train_correct / total_train_samples\n",
        "        train_err[epoch] = float(total_train_err) / total_train_samples\n",
        "        train_loss[epoch] = float(total_train_loss) / (i + 1)\n",
        "        val_acc[epoch], val_err[epoch], val_loss[epoch] = evaluate(model, val_loader, criterion)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Train Acc: {train_acc[epoch]:.4f}, Train err: {train_err[epoch]:.4f}, Train loss: {train_loss[epoch]:.4f} | Validation Acc: {val_acc[epoch]:.4f}, Validation err: {val_err[epoch]:.4f}, Validation loss: {val_loss[epoch]:.4f}\")\n",
        "\n",
        "        # Save the model every few epochs instead of every epoch\n",
        "        if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:\n",
        "            model_path = f\"model_{model.__class__.__name__}_bs{batch_size}_lr{lr}_epoch{epoch + 1}.pth\"\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print('Finished Training')\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Total time elapsed: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(f\"{model.__class__.__name__}_train_acc.csv\", train_acc)\n",
        "    np.savetxt(f\"{model.__class__.__name__}_train_err.csv\", train_err)\n",
        "    np.savetxt(f\"{model.__class__.__name__}_train_loss.csv\", train_loss)\n",
        "    np.savetxt(f\"{model.__class__.__name__}_val_acc.csv\", val_acc)\n",
        "    np.savetxt(f\"{model.__class__.__name__}_val_err.csv\", val_err)\n",
        "    np.savetxt(f\"{model.__class__.__name__}_val_loss.csv\", val_loss)\n"
      ],
      "metadata": {
        "id": "5WsZWu7HKGRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########      Plotting data from lab2        #############\n",
        "\n",
        "def plot_training_curve(path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "j2sasVAXKiZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_images = datasets.ImageFolder('/content/drive/MyDrive/aps360/Processed Data/training_database/corn', transform=transform)\n",
        "val_images = datasets.ImageFolder('/content/drive/MyDrive/aps360/Processed Data/validation_database/corn', transform=transform)\n",
        "test_images = datasets.ImageFolder('/content/drive/MyDrive/aps360/Processed Data/testing_database/corn', transform=transform)\n"
      ],
      "metadata": {
        "id": "qhfYZGsroT92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = CustomCNN(num_classes = 6)\n",
        "train(model, train_images,val_images, test_images,batch_size=64, lr=0.001, num_epochs=20)"
      ],
      "metadata": {
        "id": "MQ-HwuVioB7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e205acc3-5ca7-41f2-c567-9682824fa85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 0.5641, Train err: 0.4359, Train loss: 1.5897 | Validation Acc: 0.7262, Validation err: 0.2738, Validation loss: 0.8364\n",
            "Epoch 2: Train Acc: 0.7374, Train err: 0.2626, Train loss: 0.7855 | Validation Acc: 0.7119, Validation err: 0.2881, Validation loss: 0.6627\n",
            "Epoch 3: Train Acc: 0.7599, Train err: 0.2401, Train loss: 0.6380 | Validation Acc: 0.8190, Validation err: 0.1810, Validation loss: 0.4723\n",
            "Epoch 4: Train Acc: 0.8349, Train err: 0.1651, Train loss: 0.4641 | Validation Acc: 0.8071, Validation err: 0.1929, Validation loss: 0.4840\n",
            "Epoch 5: Train Acc: 0.8615, Train err: 0.1385, Train loss: 0.3893 | Validation Acc: 0.8405, Validation err: 0.1595, Validation loss: 0.4401\n",
            "Epoch 6: Train Acc: 0.8718, Train err: 0.1282, Train loss: 0.3574 | Validation Acc: 0.8190, Validation err: 0.1810, Validation loss: 0.4675\n",
            "Epoch 7: Train Acc: 0.8813, Train err: 0.1187, Train loss: 0.3053 | Validation Acc: 0.8143, Validation err: 0.1857, Validation loss: 0.4866\n",
            "Epoch 8: Train Acc: 0.8970, Train err: 0.1030, Train loss: 0.2690 | Validation Acc: 0.7976, Validation err: 0.2024, Validation loss: 0.5965\n",
            "Epoch 9: Train Acc: 0.9209, Train err: 0.0791, Train loss: 0.2244 | Validation Acc: 0.8238, Validation err: 0.1762, Validation loss: 0.5230\n",
            "Epoch 10: Train Acc: 0.9393, Train err: 0.0607, Train loss: 0.1727 | Validation Acc: 0.8357, Validation err: 0.1643, Validation loss: 0.4800\n",
            "Epoch 11: Train Acc: 0.9700, Train err: 0.0300, Train loss: 0.0934 | Validation Acc: 0.8405, Validation err: 0.1595, Validation loss: 0.5243\n",
            "Epoch 12: Train Acc: 0.9829, Train err: 0.0171, Train loss: 0.0607 | Validation Acc: 0.7952, Validation err: 0.2048, Validation loss: 0.6829\n",
            "Epoch 13: Train Acc: 0.9870, Train err: 0.0130, Train loss: 0.0608 | Validation Acc: 0.8143, Validation err: 0.1857, Validation loss: 0.6847\n",
            "Epoch 14: Train Acc: 0.9734, Train err: 0.0266, Train loss: 0.0884 | Validation Acc: 0.7810, Validation err: 0.2190, Validation loss: 0.8362\n",
            "Epoch 15: Train Acc: 0.9645, Train err: 0.0355, Train loss: 0.1128 | Validation Acc: 0.7857, Validation err: 0.2143, Validation loss: 0.8722\n",
            "Epoch 16: Train Acc: 0.9502, Train err: 0.0498, Train loss: 0.1450 | Validation Acc: 0.7143, Validation err: 0.2857, Validation loss: 1.6062\n",
            "Epoch 17: Train Acc: 0.9727, Train err: 0.0273, Train loss: 0.0988 | Validation Acc: 0.7952, Validation err: 0.2048, Validation loss: 0.8547\n",
            "Epoch 18: Train Acc: 0.9543, Train err: 0.0457, Train loss: 0.1616 | Validation Acc: 0.8119, Validation err: 0.1881, Validation loss: 0.7942\n",
            "Epoch 19: Train Acc: 0.9577, Train err: 0.0423, Train loss: 0.1365 | Validation Acc: 0.8143, Validation err: 0.1857, Validation loss: 0.8279\n"
          ]
        }
      ]
    }
  ]
}