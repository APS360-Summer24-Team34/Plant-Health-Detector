{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#NOTE: This copy has just what you need to instantiate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMib9LpB5yPm"
      },
      "outputs": [],
      "source": [
        "import os                       # for working with files\n",
        "import numpy as np              # for numerical computationss\n",
        "import pandas as pd             # for working with dataframes\n",
        "import torch                    # Pytorch module\n",
        "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
        "import torch.nn as nn           # for creating  neural networks\n",
        "from torch.utils.data import DataLoader # for dataloaders\n",
        "from PIL import Image           # for checking images\n",
        "import torch.nn.functional as F # for functions for calculating loss\n",
        "import torchvision.transforms as transforms   # for transforming images into tensors\n",
        "from torchvision.utils import make_grid       # for data checking\n",
        "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
        "from torchsummary import summary              # for getting the summary of our model\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YD2ZUy5_6FVJ"
      },
      "outputs": [],
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        return self.relu2(out) + x # ReLU can be applied before or after adding the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wvE3LVCP9tpK"
      },
      "outputs": [],
      "source": [
        "# for calculating the accuracy\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mwm0SaV46F_A"
      },
      "outputs": [],
      "source": [
        "# base class for the model\n",
        "class ImageClassificationBase(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                   # Generate prediction\n",
        "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        acc = accuracy(out, labels)          # Calculate accuracy\n",
        "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n",
        "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
        "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J6Gl_71D9fPy"
      },
      "outputs": [],
      "source": [
        "# convolution block with BatchNormalization\n",
        "def ConvBlock(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "             nn.BatchNorm2d(out_channels),\n",
        "             nn.ReLU(inplace=True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "# resnet architecture\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_diseases):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, 64)\n",
        "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64\n",
        "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
        "\n",
        "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
        "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
        "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(16),\n",
        "                                       nn.Flatten(),\n",
        "                                       nn.Linear(512, num_diseases))\n",
        "\n",
        "    def forward(self, xb): # xb is the loaded batch\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ms6wHNuJ9f6_"
      },
      "outputs": [],
      "source": [
        "#Instantiate model on CPU\n",
        "model = ResNet9(3, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iEdfPT7a99IQ"
      },
      "outputs": [],
      "source": [
        "# Load the model checkpoint\n",
        "def load_checkpoint(filepath, model):\n",
        "    checkpoint = torch.load(filepath, map_location=torch.device('cpu')) # Load onto CPU\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    return checkpoint['epoch']\n",
        "\n",
        "start_epoch = load_checkpoint('model_epoch_40_round_2.pth', model)\n",
        "\n",
        "# The rest of your code can remain the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjS--0ZU-XBT",
        "outputId": "4ebce71b-b41b-4aba-b65f-ff33f7f440a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cr3nEqUJ-X8J"
      },
      "outputs": [],
      "source": [
        "val_dir = '/content/drive/My Drive/1. UofT/1. Second Year/APS360/APS360 Project/Corn_Dataset/Corn_Validation'\n",
        "valid = ImageFolder(val_dir, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tDUVaf2H-nPR"
      },
      "outputs": [],
      "source": [
        "# Setting the seed value\n",
        "random_seed = 7\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# setting the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaders for validation\n",
        "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIsHXORWij_k",
        "outputId": "bf40cb30-0a01-4732-8c0a-ea763d5d3d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Acc: 0.9381, Validation err: 0.0619, Validation loss: 0.2318\n"
          ]
        }
      ],
      "source": [
        "#functions below are mostly from lab2/lab3 of APS360\n",
        "def evaluate(net, loader, criterion):\n",
        "    net.eval()\n",
        "    total_loss = 0.0\n",
        "    total_err = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            inputs, labels = data\n",
        "            #inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "            total_loss += loss.item()\n",
        "            total_err += (predicted != labels).sum().item()\n",
        "    accuracy = total_correct / total_samples\n",
        "    err = float(total_err) / total_samples\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return accuracy, err, loss\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "val_acc, val_err, val_loss = evaluate(model, valid_dl, criterion)\n",
        "\n",
        "print(f\"Validation Acc: {val_acc:.4f}, Validation err: {val_err:.4f}, Validation loss: {val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF4az2G5-Tnl",
        "outputId": "d4590309-cbd3-477f-df4b-2fabb6754309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 93.81%\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Example usage\n",
        "validation_accuracy = evaluate_model(model, valid_dl)\n",
        "print(f\"Validation Accuracy: {validation_accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
